{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# Download and import the necessary libraries\n",
        "\n",
        "!pip install torch\n",
        "!pip install numpy\n",
        "!pip install spektral # for loading and preprocessing the Cora dataset in a nice format\n",
        "\n",
        "import torch as t\n",
        "import numpy as np\n",
        "import spektral\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pa-m18QypYvN",
        "outputId": "69854802-1ae7-479b-f145-40d71404a57f"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.0.1+cu118)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch) (3.12.2)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch) (4.6.3)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch) (1.11.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.2)\n",
            "Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch) (2.0.0)\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch) (3.25.2)\n",
            "Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch) (16.0.6)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (2.1.3)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch) (1.3.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (1.22.4)\n",
            "Collecting spektral\n",
            "  Downloading spektral-1.3.0-py3-none-any.whl (140 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m140.1/140.1 kB\u001b[0m \u001b[31m13.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from spektral) (1.2.0)\n",
            "Requirement already satisfied: lxml in /usr/local/lib/python3.10/dist-packages (from spektral) (4.9.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from spektral) (3.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from spektral) (1.22.4)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from spektral) (1.5.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from spektral) (2.27.1)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from spektral) (1.2.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from spektral) (1.10.1)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from spektral) (4.65.0)\n",
            "Requirement already satisfied: tensorflow>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from spektral) (2.12.0)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.2.0->spektral) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.2.0->spektral) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=2.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.2.0->spektral) (23.5.26)\n",
            "Requirement already satisfied: gast<=0.4.0,>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.2.0->spektral) (0.4.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.2.0->spektral) (0.2.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.2.0->spektral) (1.56.0)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.2.0->spektral) (3.8.0)\n",
            "Requirement already satisfied: jax>=0.3.15 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.2.0->spektral) (0.4.10)\n",
            "Requirement already satisfied: keras<2.13,>=2.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.2.0->spektral) (2.12.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.2.0->spektral) (16.0.0)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.2.0->spektral) (3.3.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.2.0->spektral) (23.1)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.2.0->spektral) (3.20.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.2.0->spektral) (67.7.2)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.2.0->spektral) (1.16.0)\n",
            "Requirement already satisfied: tensorboard<2.13,>=2.12 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.2.0->spektral) (2.12.3)\n",
            "Requirement already satisfied: tensorflow-estimator<2.13,>=2.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.2.0->spektral) (2.12.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.2.0->spektral) (2.3.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.2.0->spektral) (4.6.3)\n",
            "Requirement already satisfied: wrapt<1.15,>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.2.0->spektral) (1.14.1)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow>=2.2.0->spektral) (0.32.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas->spektral) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->spektral) (2022.7.1)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->spektral) (1.26.16)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->spektral) (2023.5.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests->spektral) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->spektral) (3.4)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->spektral) (3.1.0)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from astunparse>=1.6.0->tensorflow>=2.2.0->spektral) (0.40.0)\n",
            "Requirement already satisfied: ml-dtypes>=0.1.0 in /usr/local/lib/python3.10/dist-packages (from jax>=0.3.15->tensorflow>=2.2.0->spektral) (0.2.0)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.13,>=2.12->tensorflow>=2.2.0->spektral) (2.17.3)\n",
            "Requirement already satisfied: google-auth-oauthlib<1.1,>=0.5 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.13,>=2.12->tensorflow>=2.2.0->spektral) (1.0.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.13,>=2.12->tensorflow>=2.2.0->spektral) (3.4.3)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.13,>=2.12->tensorflow>=2.2.0->spektral) (0.7.1)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.13,>=2.12->tensorflow>=2.2.0->spektral) (2.3.6)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow>=2.2.0->spektral) (5.3.1)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow>=2.2.0->spektral) (0.3.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow>=2.2.0->spektral) (4.9)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from google-auth-oauthlib<1.1,>=0.5->tensorboard<2.13,>=2.12->tensorflow>=2.2.0->spektral) (1.3.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard<2.13,>=2.12->tensorflow>=2.2.0->spektral) (2.1.3)\n",
            "Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow>=2.2.0->spektral) (0.5.0)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<1.1,>=0.5->tensorboard<2.13,>=2.12->tensorflow>=2.2.0->spektral) (3.2.2)\n",
            "Installing collected packages: spektral\n",
            "Successfully installed spektral-1.3.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# This notebook demos several techniques to implement Graph neural networks (GNN) and eventually uses those techniques to perform classification on the Cora dataset.\n",
        "\n",
        "# Cora\n",
        "\n",
        "Cora is a citation network. Each node in the network is a paper, and the edges between papers are citations. The purpose of the Cora benchmark is to classify papers into topics. Cora dataset details:\n",
        "\n",
        "- 2708 nodes\n",
        "- 5429 edges\n",
        "- Features are a bag-of-words\n",
        "- 7 topics\n",
        "- 140 training papers\n",
        "- 500 validation papers\n",
        "- 1000 test papers\n",
        "\n",
        "\n",
        "# Why?\n",
        "\n",
        "Graphs are everywhere. Graphs can represent chemical bonds, social media connections, transportation maps, and so much more. Much like regular neural networks, graph neural networks allow us to perform classifcation tasks and help us make informative decisions on structures that take the form of a graph.\n",
        "\n",
        "# Why not just use regular neural nets?\n",
        "\n",
        "Neural nets work really well with data that has a defined structure and order. For example, consider a classifier that works on the MNIST dataset. Each input in this dataset is an image, and images have a well defined structure: a NxN grid of pixels each with well defined values. The order of the surrounding pixels is also well defined. Graphs on the other hand, do not have a specific shape or predefined order. Thus it makes sense to use a different kind of neural network to learn about the connections in the graph.\n",
        "\n",
        "# How are GNNs implemented?\n",
        "\n",
        "The idea for GNNs are actually very similar to convolutional neural networks that work on images. In fact, we can think of an image as a graph of pixels where each pixel is connected to their 8 adjacent neighbors. When we perform a convolution, we take a kernel over these neighbors and the pixel in question, perform an element wise multiplication and aggregate these values to replace the value of the pixel in question. This idea is very similar to how we will approach a GNN.\n",
        "\n",
        "# How to implement the update rule?\n",
        "\n",
        "There are several techniques to implement the update rule for a GNN. The general form is:\n",
        "\n",
        "$$\\vec{h'_{i}} = \\sigma * \\sum_{j\\in N_i}a_{ij}W\\vec{h_j}$$\n",
        "\n",
        "Where $a_{ij}$ is a coefficient for each node in the graph. In other words, this is how important node $j$'s features are to node $i$. There are several common forms for that $a_{ij}$ can take\n",
        "\n",
        "# Sum-Pooling and Mean Sum-Pooling\n",
        "\n",
        "With basic sum-pooling, the coefficient $a_{ij}$ will take the value of 1. This will essentially just sum up the features of node $i$'s neighbors during update. However, this can cause the scale of the output features to increase. Thus, we need to normalize - introducing the mean sum-pooling form. With mean sum-pooling, the coefficient $a_{ij}$ takes the form $\\frac{1}{N_i}$. This provides a more robust approach and is very useful for induction problems.\n",
        "\n",
        "# GCN\n",
        "\n",
        "If we want to use symmetric normalization instead, the coefficient $a_{ij}$ will take the form: $\\frac{1}{\\sqrt{|N_i||N_j|}}$. This form currently represents the most popular graph convolutional layer. Benefits: Easy to scale and really powerful. Cons: Not general enough. Cannot handle complex features.\n",
        "\n",
        "# How to make the update rule more general\n",
        "\n",
        "Focus on edge-wise mechanisms. In other words we can send messages along the edges, which can be conditioned by edge features and then aggregate these messaages to update our node. This method is called a message-passing neural network (MPNN). The update rule for MPNNs take the form:\n",
        "\n",
        "$$\\vec{h'_{i}} = f_v(\\vec{h_i}\\sum_{j\\in N_i}\\vec{m_{ji}})$$\n",
        "\n",
        "where $f_v$ is some readout function, and $m_{ji}$ is a message from node $j$ to node $i$. We compute the message using a function $f_e$. $f_v$ and $f_e$ are usually small MLPs.  \n",
        "\n",
        "An MPNN is the most potent GNN layer (of the ones that only look at first order neighbors) but it has a few cons:\n",
        "\n",
        "- Requires storage and manipulation of messages\n",
        "- Can be memory-wise and representionally troublesome. Has the potential to really overfit the data or take up a lot of memory.\n",
        "\n",
        "Thus, they are only really applicable for small graphs.\n",
        "\n",
        "# GAT\n",
        "\n",
        "With GATs, we can calculate the coefficient $a_{ij}$ implicitly using some attention function $a$. $a$ can be any learnable, shared, self-attention mechanism. They may not be as general as MPNNs but they can scaled up by a lot.\n",
        "\n",
        "# Note: Transformers are GNNs! More specifically they are MPNNs.\n",
        "\n"
      ],
      "metadata": {
        "id": "BPfiQfkgk2DS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Cora\n",
        "\n",
        "Cora is a citation network. Each node in the network is a paper, and the edges between papers are citations. The purpose of the Cora benchmark is to classify papers into topics. Cora dataset details:\n",
        "\n",
        "- 2708 nodes\n",
        "- 5429 edges\n",
        "- Features are a bag-of-words\n",
        "- 7 topics\n",
        "- 140 training papers\n",
        "- 500 validation papers\n",
        "- 1000 test papers\n",
        "\n",
        "Let's load the Cora dataset and look at some of its properties."
      ],
      "metadata": {
        "id": "uj2RXO8vrPPC"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AV7aWtPfkyQS",
        "outputId": "97f764ad-0139-477a-87d7-33883ad6726e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of Nodes: 2708\n",
            "Number of Node Features: 1433\n",
            "Number of Labels: 7\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/scipy/sparse/_index.py:146: SparseEfficiencyWarning: Changing the sparsity structure of a csr_matrix is expensive. lil_matrix is more efficient.\n",
            "  self._set_arrayXarray(i, j, x)\n"
          ]
        }
      ],
      "source": [
        "# Load the Cora dataset\n",
        "cora = spektral.datasets.citation.Citation('cora')\n",
        "\n",
        "# Print the number of nodes and labels\n",
        "print(\"Number of Nodes:\", cora.n_nodes)\n",
        "print(\"Number of Node Features:\", cora.n_node_features)\n",
        "print(\"Number of Labels:\", cora.n_labels)\n",
        "\n",
        "\n",
        "\n"
      ]
    }
  ]
}